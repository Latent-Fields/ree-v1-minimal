"""
Latent Stack (L-space) Implementation

REE uses a multi-timescale latent stack representing temporally displaced
prediction depths operating over two primary representational domains:
1. A shared sensory latent that fuses modality-specific evidence
2. A downstream affordance/action latent generated by fast forward prediction

The stack is organized by timescale, not by sensory modality:
- z_gamma (γ): Shared sensory binding / feature conjunction (multimodal evidence + precision)
- z_beta (β): Affordance and immediate action-set maintenance
- z_theta (θ): Sequence context, temporal ordering, short-horizon narrative
- z_delta (δ): Regime, motivational set, long-horizon context, default-mode attractor

Downstream processes may not directly overwrite z_gamma; influence is restricted
to prediction-error updates and precision (gain) modulation.
"""

from dataclasses import dataclass
from typing import Optional, Tuple, Dict, Any

import torch
import torch.nn as nn
import torch.nn.functional as F

from ree_core.utils.config import LatentStackConfig


@dataclass
class LatentState:
    """Container for the complete latent state across all depths.

    Attributes:
        z_gamma: Sensory binding layer (shared sensory latent z_S)
        z_beta: Affordance/action layer (action latent z_A)
        z_theta: Sequence context layer
        z_delta: Regime/motivation layer
        precision: Per-depth precision values for gain modulation
        timestamp: Optional timestep for this state
    """
    z_gamma: torch.Tensor  # [batch, gamma_dim]
    z_beta: torch.Tensor   # [batch, beta_dim]
    z_theta: torch.Tensor  # [batch, theta_dim]
    z_delta: torch.Tensor  # [batch, delta_dim]
    precision: Dict[str, torch.Tensor]  # Per-depth precision values
    timestamp: Optional[int] = None

    def to_tensor(self) -> torch.Tensor:
        """Concatenate all depths into a single tensor."""
        return torch.cat([self.z_gamma, self.z_beta, self.z_theta, self.z_delta], dim=-1)

    @property
    def device(self) -> torch.device:
        """Get the device of the latent state."""
        return self.z_gamma.device

    def detach(self) -> "LatentState":
        """Return a detached copy of the latent state."""
        return LatentState(
            z_gamma=self.z_gamma.detach(),
            z_beta=self.z_beta.detach(),
            z_theta=self.z_theta.detach(),
            z_delta=self.z_delta.detach(),
            precision={k: v.detach() for k, v in self.precision.items()},
            timestamp=self.timestamp
        )


class DepthEncoder(nn.Module):
    """Encoder for a single depth level of the latent stack.

    Each depth level:
    - Receives input (observation or lower-depth state)
    - Receives top-down conditioning from higher depth
    - Produces encoded latent state
    - Maintains precision (gain) modulation
    """

    def __init__(
        self,
        input_dim: int,
        output_dim: int,
        topdown_dim: int,
        hidden_dim: int = 64,
        activation: str = "relu"
    ):
        super().__init__()
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.topdown_dim = topdown_dim

        # Main encoding path
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU() if activation == "relu" else nn.Tanh(),
            nn.Linear(hidden_dim, output_dim)
        )

        # Top-down conditioning projection
        if topdown_dim > 0:
            self.topdown_proj = nn.Linear(topdown_dim, output_dim)
        else:
            self.topdown_proj = None

        # Precision (gain) modulation - learnable per-dimension
        self.precision_logit = nn.Parameter(torch.zeros(output_dim))

    def forward(
        self,
        x: torch.Tensor,
        topdown: Optional[torch.Tensor] = None,
        precision_override: Optional[torch.Tensor] = None
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Encode input with optional top-down conditioning.

        Args:
            x: Input tensor [batch, input_dim]
            topdown: Top-down conditioning from higher depth [batch, topdown_dim]
            precision_override: Optional precision values to use instead of learned

        Returns:
            encoded: Encoded latent state [batch, output_dim]
            precision: Precision values used [batch, output_dim]
        """
        # Base encoding
        encoded = self.encoder(x)

        # Apply top-down conditioning (additive prior, not overwrite)
        if topdown is not None and self.topdown_proj is not None:
            topdown_signal = self.topdown_proj(topdown)
            encoded = encoded + topdown_signal

        # Compute precision (sigmoid to keep in [0, 1])
        if precision_override is not None:
            precision = precision_override
        else:
            precision = torch.sigmoid(self.precision_logit).unsqueeze(0).expand(x.shape[0], -1)

        # Apply precision-weighted activation
        # Higher precision = more confident encoding, lower variance
        encoded = encoded * precision

        return encoded, precision


class LatentStack(nn.Module):
    """
    Multi-timescale Latent Stack (L-space) for REE.

    Implements the hierarchical latent representation with:
    - Bottom-up encoding from observations
    - Top-down conditioning from higher depths
    - Precision-weighted prediction errors
    - Temporal update dynamics

    The stack preserves perceptual corrigibility: illusions and misperceptions
    arise from misweighted precision or suppressed error, not from semantic
    overwrite of sensory state.
    """

    def __init__(self, config: Optional[LatentStackConfig] = None):
        super().__init__()
        self.config = config or LatentStackConfig()

        # Depth encoders (bottom-up: gamma <- beta <- theta <- delta)
        # gamma receives observations directly
        self.gamma_encoder = DepthEncoder(
            input_dim=self.config.observation_dim,
            output_dim=self.config.gamma_dim,
            topdown_dim=self.config.topdown_dim,
            activation=self.config.activation
        )

        # beta receives gamma state
        self.beta_encoder = DepthEncoder(
            input_dim=self.config.gamma_dim,
            output_dim=self.config.beta_dim,
            topdown_dim=self.config.topdown_dim,
            activation=self.config.activation
        )

        # theta receives beta state
        self.theta_encoder = DepthEncoder(
            input_dim=self.config.beta_dim,
            output_dim=self.config.theta_dim,
            topdown_dim=self.config.topdown_dim,
            activation=self.config.activation
        )

        # delta receives theta state (no top-down for highest level)
        self.delta_encoder = DepthEncoder(
            input_dim=self.config.theta_dim,
            output_dim=self.config.delta_dim,
            topdown_dim=0,
            activation=self.config.activation
        )

        # Top-down projections for conditioning
        self.delta_to_theta = nn.Linear(self.config.delta_dim, self.config.topdown_dim)
        self.theta_to_beta = nn.Linear(self.config.theta_dim, self.config.topdown_dim)
        self.beta_to_gamma = nn.Linear(self.config.beta_dim, self.config.topdown_dim)

        # Prediction networks for each depth (used for prediction error computation)
        self.gamma_predictor = nn.Linear(self.config.gamma_dim, self.config.gamma_dim)
        self.beta_predictor = nn.Linear(self.config.beta_dim, self.config.beta_dim)
        self.theta_predictor = nn.Linear(self.config.theta_dim, self.config.theta_dim)
        self.delta_predictor = nn.Linear(self.config.delta_dim, self.config.delta_dim)

        # Track total dimensions
        self.total_dim = (
            self.config.gamma_dim + self.config.beta_dim +
            self.config.theta_dim + self.config.delta_dim
        )

    def init_state(self, batch_size: int = 1, device: torch.device = None) -> LatentState:
        """Initialize latent state with zeros."""
        device = device or torch.device("cpu")
        return LatentState(
            z_gamma=torch.zeros(batch_size, self.config.gamma_dim, device=device),
            z_beta=torch.zeros(batch_size, self.config.beta_dim, device=device),
            z_theta=torch.zeros(batch_size, self.config.theta_dim, device=device),
            z_delta=torch.zeros(batch_size, self.config.delta_dim, device=device),
            precision={
                "gamma": torch.ones(batch_size, self.config.gamma_dim, device=device) * 0.5,
                "beta": torch.ones(batch_size, self.config.beta_dim, device=device) * 0.5,
                "theta": torch.ones(batch_size, self.config.theta_dim, device=device) * 0.5,
                "delta": torch.ones(batch_size, self.config.delta_dim, device=device) * 0.5,
            },
            timestamp=0
        )

    def encode(
        self,
        observation: torch.Tensor,
        prev_state: Optional[LatentState] = None
    ) -> LatentState:
        """
        Encode observation into latent state with top-down conditioning.

        This implements the bottom-up pass with top-down modulation:
        1. First pass: encode each depth bottom-up
        2. Compute top-down conditioning signals
        3. Second pass: refine with top-down priors

        Args:
            observation: Raw observation [batch, observation_dim]
            prev_state: Previous latent state for temporal continuity

        Returns:
            New latent state
        """
        batch_size = observation.shape[0]
        device = observation.device

        # Initialize previous state if needed
        if prev_state is None:
            prev_state = self.init_state(batch_size, device)

        # First pass: bottom-up encoding without top-down (to get initial estimates)
        z_gamma_init, prec_gamma = self.gamma_encoder(observation)
        z_beta_init, prec_beta = self.beta_encoder(z_gamma_init)
        z_theta_init, prec_theta = self.theta_encoder(z_beta_init)
        z_delta, prec_delta = self.delta_encoder(z_theta_init)

        # Compute top-down conditioning signals
        topdown_theta = self.delta_to_theta(z_delta)
        topdown_beta = self.theta_to_beta(z_theta_init)
        topdown_gamma = self.beta_to_gamma(z_beta_init)

        # Second pass: refine with top-down conditioning
        z_theta, prec_theta = self.theta_encoder(z_beta_init, topdown_theta)
        topdown_beta = self.theta_to_beta(z_theta)  # Update with refined theta

        z_beta, prec_beta = self.beta_encoder(z_gamma_init, topdown_beta)
        topdown_gamma = self.beta_to_gamma(z_beta)  # Update with refined beta

        z_gamma, prec_gamma = self.gamma_encoder(observation, topdown_gamma)

        # Temporal smoothing with previous state (exponential moving average)
        alpha = 0.3  # Temporal smoothing factor
        z_gamma = alpha * z_gamma + (1 - alpha) * prev_state.z_gamma
        z_beta = alpha * z_beta + (1 - alpha) * prev_state.z_beta
        z_theta = alpha * z_theta + (1 - alpha) * prev_state.z_theta
        z_delta = alpha * z_delta + (1 - alpha) * prev_state.z_delta

        return LatentState(
            z_gamma=z_gamma,
            z_beta=z_beta,
            z_theta=z_theta,
            z_delta=z_delta,
            precision={
                "gamma": prec_gamma,
                "beta": prec_beta,
                "theta": prec_theta,
                "delta": prec_delta,
            },
            timestamp=(prev_state.timestamp or 0) + 1
        )

    def predict(self, state: LatentState) -> LatentState:
        """
        Predict next latent state from current state.

        Used for trajectory rollouts and computing prediction errors.

        Args:
            state: Current latent state

        Returns:
            Predicted next latent state
        """
        z_gamma_pred = self.gamma_predictor(state.z_gamma)
        z_beta_pred = self.beta_predictor(state.z_beta)
        z_theta_pred = self.theta_predictor(state.z_theta)
        z_delta_pred = self.delta_predictor(state.z_delta)

        return LatentState(
            z_gamma=z_gamma_pred,
            z_beta=z_beta_pred,
            z_theta=z_theta_pred,
            z_delta=z_delta_pred,
            precision=state.precision,  # Maintain precision
            timestamp=(state.timestamp or 0) + 1
        )

    def compute_prediction_error(
        self,
        predicted: LatentState,
        actual: LatentState
    ) -> Dict[str, torch.Tensor]:
        """
        Compute precision-weighted prediction errors at each depth.

        Prediction errors are the driving signal for learning and
        are routed differently depending on depth:
        - gamma: Perceptual error -> update perceptual priors
        - beta: Affordance error -> update E2 rollout model
        - theta/delta: Deep model error -> update E1 world model

        Args:
            predicted: Predicted latent state
            actual: Actual observed latent state

        Returns:
            Dictionary of precision-weighted errors per depth
        """
        errors = {}

        # Raw errors
        gamma_error = actual.z_gamma - predicted.z_gamma
        beta_error = actual.z_beta - predicted.z_beta
        theta_error = actual.z_theta - predicted.z_theta
        delta_error = actual.z_delta - predicted.z_delta

        # Precision-weighted errors
        errors["gamma"] = gamma_error * actual.precision["gamma"]
        errors["beta"] = beta_error * actual.precision["beta"]
        errors["theta"] = theta_error * actual.precision["theta"]
        errors["delta"] = delta_error * actual.precision["delta"]

        # Total error magnitude (for monitoring)
        errors["total"] = (
            errors["gamma"].pow(2).mean() +
            errors["beta"].pow(2).mean() +
            errors["theta"].pow(2).mean() +
            errors["delta"].pow(2).mean()
        )

        return errors

    def modulate_precision(
        self,
        state: LatentState,
        depth: str,
        gain: float
    ) -> LatentState:
        """
        Modulate precision at a specific depth.

        Attention is implemented as precision (gain) modulation.
        Higher precision = more weight on that depth's signals.

        Args:
            state: Current latent state
            depth: Which depth to modulate ("gamma", "beta", "theta", "delta")
            gain: Multiplicative gain factor

        Returns:
            State with modulated precision
        """
        new_precision = state.precision.copy()
        new_precision[depth] = torch.clamp(
            state.precision[depth] * gain,
            min=0.01,
            max=1.0
        )

        return LatentState(
            z_gamma=state.z_gamma,
            z_beta=state.z_beta,
            z_theta=state.z_theta,
            z_delta=state.z_delta,
            precision=new_precision,
            timestamp=state.timestamp
        )

    def get_shared_sensory_latent(self, state: LatentState) -> torch.Tensor:
        """Get z_S (shared sensory latent) = z_gamma."""
        return state.z_gamma

    def get_affordance_latent(self, state: LatentState) -> torch.Tensor:
        """Get z_A (affordance/action latent) = z_beta."""
        return state.z_beta

    def forward(
        self,
        observation: torch.Tensor,
        prev_state: Optional[LatentState] = None
    ) -> LatentState:
        """Forward pass: encode observation into latent state."""
        return self.encode(observation, prev_state)
